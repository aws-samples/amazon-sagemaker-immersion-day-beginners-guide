{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1314fc53",
   "metadata": {},
   "source": [
    "# Notebook 2 - Run Processing and Training using SageMaker Resources\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Source the libraries](#Source-the-libraries)\n",
    "1. [Task 1: Set Up Global Variables](#Task-1:-Set-Up-Global-Variables)\n",
    "1. [Task 2: Run the Data Processing Job](#Task-2:-Run-the-Data-Processing-Job)\n",
    "1. [Task 3: Run the Model Training Job](#Task-3:-Run-the-Model-Training-Job)\n",
    "1. [Task 4: Deploy the Endpoint](#Task-4:-Deploy-the-Endpoint)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c6011",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates the use of Amazon SageMaker XGBoost to process data, train a model and host an endpoint using [SageMaker](https://docs.aws.amazon.com/sagemaker/index.html) Resources.\n",
    "\n",
    "We use the [Predictive Maintenance Dataset](https://static.us-east-1.prod.workshops.aws/public/6f2f7cb1-bfda-4b34-ae39-928502784393/static/datasets/maintenance_dataset.csv), originally from the [UCI data repository](http://archive.ics.uci.edu/ml). More details about the original dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset).\n",
    "\n",
    "---\n",
    "## Sourcing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb508f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 1\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a992e81",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Set Up Global Variables\n",
    "**Steps**\n",
    "* Put the name of your bucket and file name into S3_BUCKET and KEY respectively - as you did in the previous notebook `cell 2`\n",
    "* Optional: Change the `PREFIX` name (not mandatory) `cell 2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d1775",
   "metadata": {},
   "source": [
    "### Set S3 bucket and data prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615851ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 2\n",
    "\n",
    "# Provide information to where the training and validation data will be uploaded to \n",
    "S3_BUCKET = 'YOUR_S3_BUCKET' # YOUR_S3_BUCKET\n",
    "KEY = \"YOUR_OBJECT_ON_S3\" # YOUR_OBJECT_ON_S3\n",
    "PREFIX = 'pred-maintenance'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb25e8a",
   "metadata": {},
   "source": [
    "### Set role and global vars\n",
    "\n",
    "We are going to set the global variables that are going to be used by the SageMaker Resources, `cell 3`:\n",
    "* `sagemaker_session` is an object that manage interactions with the Amazon SageMaker APIs and any other AWS services needed.\n",
    "* `region` is the AWS Region where you want to create your object \n",
    "* `role` is the IAM role that the instances will use when executing a job.\n",
    "\n",
    "In this notebook, we will move data processing, model training and inference into [SageMaker Docker containers](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers.html). For each Sagemaker Job, a new instance is started to execute the code. The instance specifications are defined in `cell 3`.\n",
    "\n",
    "To get familiar with the [SageMaker](https://docs.aws.amazon.com/sagemaker/index.html) resources, also look at:\n",
    "* [SageMaker Python SDK Documentation](https://sagemaker.readthedocs.io/en/stable/#)\n",
    "* [Sagemaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3 \n",
    "\n",
    "# Get a SageMaker-compatible role used by this function and the session.\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "# Set your instance count and type\n",
    "instance_type = 'ml.m5.xlarge'\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ff10f",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: Run the Data Processing Job\n",
    "\n",
    "In this task, we are going to run a processing script using [SageMaker Processing Job](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_processing/scikit_learn_data_processing_and_model_evaluation/scikit_learn_data_processing_and_model_evaluation.html). To do so, we:\n",
    "1. Instantiate the Processor by specifying the Docker image location and the instance specifications\n",
    "1. We start the Processing Job by specifying the script to run, the inputs and the outputs.\n",
    "\n",
    "Before you can run this code, please update the file found under `src/preprocessor.py` by adding the required code snippets from your notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "* Open the notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`\n",
    "* Open the file `src/preprocessor.py`\n",
    "* Fill the `ACTION` parts of the `preprocess.py` file by copy & pasting your code from the notebook\n",
    "    * Here we copy the `feature_column_names` and `label_column` as well as the `train_test_split`\n",
    "    \n",
    "### Retrieve the XGBoost image from SageMaker and instantiate the Processor\n",
    "In `cell 4`, we are:\n",
    "* Retreiving the location of the XGBoost Docker Image from [Amazon Elastic Container Registry (Amazon ECR)](https://aws.amazon.com/ecr/). \n",
    "* Definition the Processor by specifying the location of the docker image and the isntance specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4 \n",
    "\n",
    "# retrieving the image location on Amazon ECR\n",
    "framework_version = \"1.3-1\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=framework_version,\n",
    "    py_version=\"py3\",\n",
    "    instance_type=instance_type)\n",
    "\n",
    "# Defining the Processor\n",
    "script_processor = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    base_job_name=PREFIX,\n",
    "    command=[\"python3\"],\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    volume_size_in_gb=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab7fc01",
   "metadata": {},
   "source": [
    "### Running the Processing Job\n",
    "\n",
    "Running `cell 5` will start an [SageMaker Processing Job](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_processing/scikit_learn_data_processing_and_model_evaluation/scikit_learn_data_processing_and_model_evaluation.html). The processing job will take about 4-5 minutes to complete. \n",
    "\n",
    "To start the SageMaker Processing job, we specify:\n",
    "* `code` - this can be an S3 URI or a local path to a file with the framework script to run.\n",
    "* `arguments` - a list of string arguments to be passed to a processing job\n",
    "* `outputs` - list of the outputs for the processing job. \n",
    "You can refer to the [SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html) to find out about the other possible arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5\n",
    "\n",
    "script_processor.run(\n",
    "    code=\"src/preprocess.py\", # point to your file\n",
    "    arguments=[\"--input-data\", f\"s3://{S3_BUCKET}/{KEY}\"], # tell the script where to find your input data\n",
    "    outputs=[ # make sure that all files saved in the container are properly synced back to S3\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534311df",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Run the Model Training Job\n",
    "\n",
    "Before you can run this code, please update the file found under `src/train.py` by adding the required code snippets from your notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "* Open the notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`\n",
    "* Open the file `src/train.py`\n",
    "* Fill the `ACTION` parts of the `train.py` file by copy & pasting your code from the notebook\n",
    "    * Here we copy the `numeric_features` and `categorical_features`\n",
    "    * Create an `X_train`, `y_train`, `X_val` and `y_val` from your datasets\n",
    "    * Add your model code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c037e",
   "metadata": {},
   "source": [
    "### Create your training container/estimator in SageMaker\n",
    "\n",
    "In `cell 6`, we define an XGBoost Estimator by specifying:\n",
    "* the location of the training script\n",
    "* the hyper parameters\n",
    "* the role and instance specification\n",
    "* output path on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768fcf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6\n",
    "\n",
    "# Set your code folder\n",
    "source_dir = 'src/'\n",
    "entry_point = 'train.py'\n",
    "\n",
    "# Set the hyperparamters for this estimator\n",
    "hyperparameters = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=entry_point,\n",
    "    source_dir=source_dir,\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    framework_version=framework_version,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    output_path=f's3://{S3_BUCKET}/{PREFIX}/model/',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b753a9",
   "metadata": {},
   "source": [
    "### Run the Training Job\n",
    "\n",
    "Running `cell 7` will start an [SageMaker Training Job](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-mkt-algo-train.html). The training job will take about 4-5 minutes to complete. \n",
    "\n",
    "To start the SageMaker Processing job, we specify:\n",
    "* `inputs` - inputs for the training job. Refer to the [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit) for additional information regarding the different supported formats.\n",
    "You can refer to the [SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit) to find out about the other possible arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e021e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 7\n",
    "\n",
    "# Train the model\n",
    "xgb_estimator.fit({\n",
    "    'train': script_processor.jobs[-1].outputs[0].destination,\n",
    "    'validation': script_processor.jobs[-1].outputs[1].destination})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f172da3",
   "metadata": {},
   "source": [
    "## Task 4: Deploy the Endpoint\n",
    "\n",
    "In `cell 8`, we deploy a [SageMaker Endpoint](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.deploy)...  That will take another 4-5 minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 8\n",
    "\n",
    "endpoint_name = \"predictive-maintenance-endpoint\"\n",
    "xgb_estimator.deploy(\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d258e2",
   "metadata": {},
   "source": [
    "### Test the endpint\n",
    "\n",
    "Let's test the endpoint. \n",
    "\n",
    "In `cell 9`, we read the data in. In `cell 10`, we make sure you drop the target column since the model expects a DataFrame with all columns except for the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599c8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 9\n",
    "\n",
    "print(\"Downloading data from bucket: %s, key: %s\", S3_BUCKET, KEY)\n",
    "fn = \"maintenance_dataset.csv\"\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(S3_BUCKET).download_file(KEY, fn)\n",
    "\n",
    "print(\"Reading downloaded data.\")\n",
    "df = pd.read_csv(fn)\n",
    "os.unlink(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbba745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 10\n",
    "\n",
    "df = df.drop(\"Failure Type\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5bfd0a",
   "metadata": {},
   "source": [
    "In `cell 11`, we test the endpoint using [Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime.html). \n",
    "1. We create a [SageMaker Runtime Client](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime.html)\n",
    "2. We use the client to invoke a an endpoint. Please refer to the [documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime.html#SageMakerRuntime.Client.invoke_endpoint), for addition information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c07ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "\n",
    "client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"text/csv\",\n",
    "    Body=df.iloc[:10, :].to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63501126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12\n",
    "\n",
    "response[\"Body\"].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b39a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
