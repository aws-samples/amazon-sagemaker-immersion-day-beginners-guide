{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac20a4f2",
   "metadata": {},
   "source": [
    "# Build a SageMaker Pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Source the libraries](#Source-the-libraries)\n",
    "1. [Task 1: Set Up Global Variables](#Task-1:-Set-Up-Global-Variables)\n",
    "1. [Task 2: Define the Processing Step](#Task-2:-Define-the-Processing-Step)\n",
    "1. [Task 3: Define the Training Step](#Task-3:-Define-the-Training-Step)\n",
    "1. [Task 4: Register your model](#Task-4:-Register-your-model)\n",
    "1. [Task 5: Define the SageMaker Pipeline](#Task-5:-Define-the-SageMaker-Pipeline)\n",
    "1. [Task 6: Start and Monitor the SageMaker Pipeline Execution](#Task-6:-Start-and-Monitor-the-SageMakerPipeline-Execution)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534cbfb7",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates the use of Amazon SageMaker XGBoost to process data, train a model and register the model.  We will be orchestrating the steps using [Amazon SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/). To get familiar with the SageMaker Pipeline, also look at:\n",
    "* [Sagemaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html)\n",
    "* [Sagemaker Python SDK Documentation](https://sagemaker.readthedocs.io/en/stable/#) \n",
    "\n",
    "We use the [Predictive Maintenance Dataset](https://static.us-east-1.prod.workshops.aws/public/6f2f7cb1-bfda-4b34-ae39-928502784393/static/datasets/maintenance_dataset.csv), originally from the [UCI data repository](http://archive.ics.uci.edu/ml). More details about the original dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset).\n",
    "\n",
    "---\n",
    "## Sourcing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb89ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 1\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.pipeline import PipelineModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5823151",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Set Up Global Variables\n",
    "\n",
    "**Steps**\n",
    "* Put the name of your bucket and filenmae into S3_BUCKET and KEY respectively - as you did in the previous notebook `cell 2`\n",
    "* Optional: Change the `PREFIX` name (not mandatory) `cell 2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8fa3e",
   "metadata": {},
   "source": [
    "### Set S3 bucket and data prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a18437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 2\n",
    "\n",
    "# Provide information to where the training and validation data will be uploaded to \n",
    "S3_BUCKET = 'YOUR_S3_BUCKET' # YOUR_S3_BUCKET\n",
    "KEY = \"YOUR_OBJECT_ON_S3\" # YOUR_OBJECT_ON_S3\n",
    "PREFIX = 'pred-maintenance'\n",
    "input_data = f\"s3://{S3_BUCKET}/{KEY}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00566ed",
   "metadata": {},
   "source": [
    "### Set role and global vars\n",
    "\n",
    "We are going to set the global variables that are going to be used by the SageMaker Resources, `cell 3`:\n",
    "* `sagemaker_session` is an object that manage interactions with the Amazon SageMaker APIs and any other AWS services needed.\n",
    "* `region` is the AWS Region where you want to create your object \n",
    "* `role` is the IAM role that the instances will use when executing a job.\n",
    "\n",
    "In the same way as in `ImmersionDay_Notebook2_SageMaker_Resources.ipynb`, in this notebook, the data processing, model training and inference step are runnig using [SageMaker Docker containers](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers.html). For each step, a new instance is started to execute the code. The instance specifications are defined in `cell 3`.\n",
    "\n",
    "To get familiar with the [SageMaker](https://docs.aws.amazon.com/sagemaker/index.html) resources, also look at:\n",
    "* [SageMaker Python SDK Documentation](https://sagemaker.readthedocs.io/en/stable/#)\n",
    "* [Sagemaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36229afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3\n",
    "\n",
    "# Get a SageMaker-compatible role used by this function and the session.\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "# Set your instance count and type\n",
    "framework_version = \"1.3-1\"\n",
    "instance_type = 'ml.m5.xlarge'\n",
    "model_package_group_name = 'pred-maintenance-model'\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd6b1ee",
   "metadata": {},
   "source": [
    "## Task 2: Define the Processing Step\n",
    "\n",
    "In this task, we are going to run a processing script using [SageMaker Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing). To do so, we:\n",
    "1. Instantiate the Processor by specifying the Docker image location and the instance specifications\n",
    "1. We define the Processing Step by specifying the script to run, the inputs and the outputs.\n",
    "\n",
    "Before you can run this code, please update the file found under `src/preprocessor.py` by adding the required code snippets from your notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "* Open the notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`\n",
    "* Open the file `src/preprocessor.py`\n",
    "* Fill the `ACTION` parts of the `preprocess.py` file by copy & pasting your code from the notebook\n",
    "    * Here we copy the `feature_column_names` and `label_column` as well as the `train_test_split`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bed8408",
   "metadata": {},
   "source": [
    "### Retrieve the XGBoost image from SageMaker and instantiate the Processor\n",
    "\n",
    "In `cell 4`, we are:\n",
    "* Retreiving the location of the XGBoost Docker Image from [Amazon Elastic Container Registry (Amazon ECR)](https://aws.amazon.com/ecr/). \n",
    "* Definition the Processor by specifying the location of the docker image and the instance specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe66177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4 \n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=framework_version,\n",
    "    py_version=\"py3\",\n",
    "    instance_type=instance_type,)\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    base_job_name=PREFIX,\n",
    "    command=[\"python3\"],\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    volume_size_in_gb=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784cf752",
   "metadata": {},
   "source": [
    "### Creating a Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5\n",
    "\n",
    "# Define the processing step\n",
    "step_process = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    processor=script_processor,\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "    ],\n",
    "    code=\"src/preprocess.py\",\n",
    "    job_arguments=[\"--input-data\", input_data],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f1966b",
   "metadata": {},
   "source": [
    "## Task 3: Define the Training Step\n",
    "\n",
    "Before you can run this code, please update the file found under `src/train.py` by adding the required code snippets from your notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "* Open the notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`\n",
    "* Open the file `src/train.py`\n",
    "* Fill the `ACTION` parts of the `train.py` file by copy & pasting your code from the notebook\n",
    "    * Here we copy the `numeric_features` and `categorical_features`\n",
    "    * Create an `X_train`, `y_train`, `X_val` and `y_val` from your datasets\n",
    "    * Add your model code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed12468f",
   "metadata": {},
   "source": [
    "### Create your training container/estimator in SageMaker\n",
    "\n",
    "In `cell 6`, we define an XGBoost Estimator by specifying:\n",
    "* the location of the training script\n",
    "* the hyper parameters\n",
    "* the role and instance specification\n",
    "* output path on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f177301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6\n",
    "\n",
    "# Set your code folder\n",
    "source_dir = 'src/'\n",
    "entry_point = 'train.py'\n",
    "\n",
    "# Set the hyperparamters for this estimator\n",
    "hyperparameters = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=entry_point,\n",
    "    source_dir=source_dir,\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    framework_version=framework_version,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    output_path=f's3://{S3_BUCKET}/{PREFIX}/model/',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e1bf17",
   "metadata": {},
   "source": [
    "### Creating a Training Step\n",
    "\n",
    "Get familiar with the pipeline, also look at here https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_building_pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1a2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell 7\n",
    "\n",
    "# Define the training step\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=xgb_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248580d",
   "metadata": {},
   "source": [
    "## Task 4: Register your model\n",
    "\n",
    "In this task, we register the estimator with [Sagemaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html). With the SageMaker Model Registry you can manager model versions and deploy models to productions as SageMaker Endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482880cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 8 \n",
    "\n",
    "# Register your model\n",
    "step_register = RegisterModel(\n",
    "    name=\"RegisterModel\",\n",
    "    estimator=xgb_estimator,\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855e8c5d",
   "metadata": {},
   "source": [
    "## Task 5: Define the SageMaker Pipeline\n",
    "\n",
    "Run through the cells below to:\n",
    "1. Define the SageMaker Pipeline `cell 9`\n",
    "2. Submit the pipeline definition to the SageMaker Pipelines service to create a pipeline if it doesn't exist, or update the pipeline if it does `cell 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 9\n",
    "\n",
    "# Pipeline instance\n",
    "pipeline = Pipeline(\n",
    "    name=\"PredMainPipeline\",\n",
    "    parameters=[\n",
    "        instance_type,\n",
    "        instance_count,\n",
    "        input_data\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_register],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db23aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 10\n",
    "\n",
    "# Create or upsert the pipeline definition\n",
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d0108",
   "metadata": {},
   "source": [
    "## Task 6: Start and Monitor the SageMaker Pipeline Execution\n",
    "\n",
    "In this task we are going to:\n",
    "1. Start the pipeline `cell 11`\n",
    "2. Examine and monitor a pipeline execution\n",
    "    * Run `cell 12` to describe the pipeline execution status to ensure that it has been created and started successfully.\n",
    "    * Run `cell 13` to list the execution steps and their status.\n",
    "    * (Optional) For those who are using SageMaker Studio, visualise the pipeline exection as described in the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-studio-view-execution.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeaca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "\n",
    "# Start the pipeline\n",
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c387c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12\n",
    "\n",
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2598de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 13\n",
    "\n",
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3199980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
