{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a343a022",
   "metadata": {},
   "source": [
    "# Build a SageMaker Pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Source the libraries](#Source-the-libraries)\n",
    "1. [Task 1: Set Up Global Variables](#Task-1:-Set-Up-Global-Variables)\n",
    "1. [Task 2: Define the Step Function Execution Inputs](#Task-2:-Define-the-Step-Function-Execution-Inputs)\n",
    "1. [Task 3: Define the Processing Step](#Task-3:-Define-the-Processing-Step)\n",
    "1. [Task 4: Define the Training Step](#Task-4:-Define-the-Training-Step)\n",
    "1. [Task 5: Define the Endpoint Steps](#Task-5:-Define-the-Endpoint-Steps)\n",
    "1. [Task 6: Define the Step Function Workflow](#Task-6:-Define-the-Step-Function-Workflow)\n",
    "1. [Task 7: Start and Monitor the Step Function Workflow](#Task-7:-Start-and-Monitor-the-Step-Function-Workflow)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e22a79",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates the use of Amazon SageMaker XGBoost to process data, train a model and host an endpoint. We will be orchestrating the steps using [AWS Step Functions](https://aws.amazon.com/step-functions/?step-functions.sort-by=item.additionalFields.postDateTime&step-functions.sort-order=desc). \n",
    "\n",
    "We use the [Predictive Maintenance Dataset](https://static.us-east-1.prod.workshops.aws/public/6f2f7cb1-bfda-4b34-ae39-928502784393/static/datasets/maintenance_dataset.csv), originally from the [UCI data repository](http://archive.ics.uci.edu/ml). More details about the original dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18fb948",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Add a policy to your SageMaker role in IAM\n",
    "\n",
    "**If you are running this notebook on an Amazon SageMaker notebook instance**, the IAM role assumed by your notebook instance needs permission to create and run workflows in AWS Step Functions. To provide this permission to the role, do the following.\n",
    "\n",
    "1. Open the Amazon [SageMaker console](https://console.aws.amazon.com/sagemaker/). \n",
    "2. Select **Notebook instances** and choose the name of your notebook instance\n",
    "3. Under **Permissions and encryption** select the role ARN to view the role on the IAM console\n",
    "4. Choose **Attach policies** and search for `AWSStepFunctionsFullAccess`.\n",
    "5. Select the check box next to `AWSStepFunctionsFullAccess` and choose **Attach policy**\n",
    "\n",
    "If you are running this notebook in a local environment, the SDK will use your configured AWS CLI configuration. For more information, see [Configuring the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html).\n",
    "\n",
    "Next, create an execution role in IAM for Step Functions. \n",
    "\n",
    "### Create an execution role for Step Functions\n",
    "\n",
    "You need an execution role so that you can create and execute workflows in Step Functions.\n",
    "\n",
    "1. Go to the [IAM console](https://console.aws.amazon.com/iam/)\n",
    "2. Select **Roles** and then **Create role**.\n",
    "3. Under **Choose the service that will use this role** select **Step Functions**\n",
    "4. Choose **Next** until you can enter a **Role name**\n",
    "5. Enter a name such as `AmazonSageMaker-StepFunctionsWorkflowExecutionRole` and then select **Create role**\n",
    "\n",
    "\n",
    "Attach a policy to the role you created. The following steps attach a policy that provides full access to Step Functions, however as a good practice you should only provide access to the resources you need.  \n",
    "\n",
    "1. Under the **Add Permissions** tab, click **Attach policy**. Select the following AWS Managed Policies:\n",
    "    - `AmazonSageMakerFullAccess`\n",
    "    - `CloudWatchFullAccess`\n",
    "    - `CloudWatchEventsFullAccess`\n",
    "\n",
    "2. Click **Attach Policy** \n",
    "3. Copy and save the **Role ARN** at the top of the **Summary**. We will use it in [Task 1](#Task-1:-Set-Up-Global-Variables)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b814d",
   "metadata": {},
   "source": [
    "## Sourcing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8f2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 1\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install stepfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838dba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 2\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "import stepfunctions\n",
    "from stepfunctions import steps\n",
    "from stepfunctions.inputs import ExecutionInput\n",
    "from stepfunctions.workflow import Workflow\n",
    "\n",
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e0789",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Set Up Global Variables\n",
    "\n",
    "**Steps**\n",
    "* Put the name of your bucket and filename into S3_BUCKET and KEY respectively - as you did in the previous notebook `cell 3`\n",
    "* Optional: Change the `PREFIX` name (not mandatory) `cell 3`\n",
    "* Compare the ARN saved in the [Setup](#Setup) with the ARN printed in `cell 4`. They should be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025f68fe",
   "metadata": {},
   "source": [
    "### Set S3 bucket and data prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3\n",
    "\n",
    "# Provide information to where the training and validation data will be uploaded to \n",
    "S3_BUCKET = 'YOUR_S3_BUCKET' # YOUR_S3_BUCKET\n",
    "KEY = \"YOUR_OBJECT_ON_S3\" # YOUR_OBJECT_ON_S3\n",
    "PREFIX = 'pred-maintenance'\n",
    "input_data = f\"s3://{S3_BUCKET}/{KEY}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf34b91",
   "metadata": {},
   "source": [
    "### Set role and global vars\n",
    "\n",
    "We are going to set the global variables that are going to be used by the SageMaker Resources, `cell 4`:\n",
    "* `sagemaker_session` is an object that manage interactions with the Amazon SageMaker APIs and any other AWS services needed.\n",
    "* `region` is the AWS Region where you want to create your object \n",
    "* `role` is the IAM role that the instances will use when executing a job.\n",
    "\n",
    "In the same way as in `ImmersionDay_Notebook2_SageMaker_Resources.ipynb`, in this notebook, the data processing, model training and inference step are runnig using [SageMaker Docker containers](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers.html). For each step, a new instance is started to execute the code. The instance specifications are defined in `cell 4`.\n",
    "\n",
    "To get familiar with the [SageMaker](https://docs.aws.amazon.com/sagemaker/index.html) resources, also look at:\n",
    "* [SageMaker Python SDK Documentation](https://sagemaker.readthedocs.io/en/stable/#)\n",
    "* [Sagemaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566061f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4\n",
    "\n",
    "# Get a SageMaker-compatible role used by this function and the session.\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "# the step functions execution role\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "workflow_execution_role = \"arn:aws:iam::{}:role/AmazonSageMaker-StepFunctionsWorkflowExecutionRole\".format(account)\n",
    "print(\"The Step Function Execution Role ARN: \", workflow_execution_role)\n",
    "\n",
    "# Set your instance count and type\n",
    "instance_type = 'ml.m5.xlarge'\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a50638",
   "metadata": {},
   "source": [
    "## Task 2: Define the Step Function Execution Inputs\n",
    "We will be orchastrating the steps using [AWS Step Functions](https://aws.amazon.com/step-functions/?step-functions.sort-by=item.additionalFields.postDateTime&step-functions.sort-order=desc). To get familiar with the Step Functions, also look at:\n",
    "* [Step Functions Developer Guide](https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html)\n",
    "* [Step Function Python SDK Documentation](https://aws-step-functions-data-science-sdk.readthedocs.io/en/stable/#).\n",
    "\n",
    "Through out the Lab, you cn refer to the [Step Function Python SDK Documentation](https://aws-step-functions-data-science-sdk.readthedocs.io/en/stable/#) and the [Sagemaker Python SDK Documentation](https://sagemaker.readthedocs.io/en/stable/#) for a better understanding of the inputs and outputs\n",
    "\n",
    "TODO add an image of the step function workflow\n",
    "\n",
    "In `cell 5`, we define the execution schema and the execution input placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2cd56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5\n",
    "\n",
    "# define the execution input schema\n",
    "schema = {\n",
    "    \"ProcessingJobName\": str,\n",
    "    \"TrainingJobName\": str,\n",
    "    \"ModelName\": str,\n",
    "    \"EndpointName\": str,\n",
    "}\n",
    "\n",
    "# define the execution input placeholders, which needs to be passed in this format to the state machine\n",
    "execution_input = ExecutionInput(schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabbf7be",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Define the Processing Step\n",
    "\n",
    "In this task, we are going to run a processing script using [SageMaker Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing). To do so, we:\n",
    "1. Instantiate the Processor by specifying the Docker image location and the instance specifications\n",
    "1. We define the Processing Step by specifying the script to run, the inputs and the outputs.\n",
    "\n",
    "Before you can run this code, please update the file found under `src/preprocessor.py` by adding the required code snippets from your notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "* Open the notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`\n",
    "* Open the file `src/preprocessor.py`\n",
    "* Fill the `ACTION` parts of the `preprocess.py` file by copy & pasting your code from the notebook\n",
    "    * Here we copy the `feature_column_names` and `label_column` as well as the `train_test_split`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78def3",
   "metadata": {},
   "source": [
    "### Retrieve the XGBoost image from SageMaker and instantiate the Processor\n",
    "In `cell 6`, we are:\n",
    "* Retreiving the location of the XGBoost Docker Image from [Amazon Elastic Container Registry (Amazon ECR)](https://aws.amazon.com/ecr/). \n",
    "* Definition the Processor by specifying the location of the docker image and the instance specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6\n",
    "\n",
    "framework_version = \"1.3-1\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=framework_version,\n",
    "    py_version=\"py3\",\n",
    "    instance_type=instance_type)\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    base_job_name=PREFIX,\n",
    "    command=[\"python3\"],\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    volume_size_in_gb=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd296836",
   "metadata": {},
   "source": [
    "### Creating a Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2184c1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 7\n",
    "\n",
    "# Uploading your code folder\n",
    "gid = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "input_processing_code = sagemaker_session.upload_data(\n",
    "    \"src/preprocess.py\",\n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix=f\"{PREFIX}/{gid}/code\",\n",
    ")\n",
    "\n",
    "\n",
    "# SageMaker Processing\n",
    "inputs = [\n",
    "    ProcessingInput(\n",
    "        source=input_processing_code,\n",
    "        destination=\"/opt/ml/processing/input/code\",\n",
    "        input_name=\"code\",\n",
    "    ),\n",
    "]\n",
    "preprocess_step = steps.ProcessingStep(\n",
    "    'Preprocess Data',\n",
    "    processor=script_processor,\n",
    "    job_name=execution_input['ProcessingJobName'],\n",
    "    inputs=inputs,\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination=f\"s3://{S3_BUCKET}/stepfunctions/output/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\", destination=f\"s3://{S3_BUCKET}/stepfunctions/output/validation\"),\n",
    "    ],\n",
    "    container_arguments=[\"--input-data\", input_data],\n",
    "    container_entrypoint = [\"python3\", \"/opt/ml/processing/input/code/preprocess.py\"],\n",
    "    wait_for_completion=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dace54b",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4: Define the Training Step\n",
    "Before you can run this code, please update the file found under `src/train.py` by adding the required code snippets from your notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "* Open the notebook `ImmersionDay_Notebook1_GettingStarted.ipynb`\n",
    "* Open the file `src/train.py`\n",
    "* Fill the `ACTION` parts of the `train.py` file by copy & pasting your code from the notebook\n",
    "    * Here we copy the `numeric_features` and `categorical_features`\n",
    "    * Create an `X_train`, `y_train`, `X_val` and `y_val` from your datasets\n",
    "    * Add your model code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec58194",
   "metadata": {},
   "source": [
    "### Create your training container/estimator in SageMaker\n",
    "\n",
    "In `cell 8`, we define an XGBoost Estimator by specifying:\n",
    "* the location of the training script\n",
    "* the hyper parameters\n",
    "* the role and instance specification\n",
    "* output path on S3\n",
    "\n",
    "### Create your training container/estimator in SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 8\n",
    "\n",
    "# Set your code folder\n",
    "entry_point = 'src/train.py'\n",
    "\n",
    "# Set the hyperparamters for this estimator\n",
    "hyperparameters = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=entry_point,\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    framework_version=framework_version,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    output_path=f's3://{S3_BUCKET}/{PREFIX}/model/',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee7339b",
   "metadata": {},
   "source": [
    "### Create your Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a1361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 9\n",
    "\n",
    "# Set the model training step\n",
    "train_step = steps.TrainingStep(\n",
    "    'Train Model',\n",
    "    estimator=xgb_estimator,\n",
    "    data={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=preprocess_step.output()['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'],\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=preprocess_step.output()['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'],\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    "    job_name=execution_input['TrainingJobName'],\n",
    "    wait_for_completion=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d307e53",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Task 5: Define the Endpoint Steps\n",
    "\n",
    "Run throught the cells below to:\n",
    "1. Create a Model Step in `cell 10` which [creates a model in SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateModel.html) from the trained estimator\n",
    "1. Create a Endpoint Configuration Step in `cell 11` which [create an endpoint configuration in SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateEndpointConfig.html).\n",
    "1. Creates an Endpoint Step in `cell 12` to create or update an endpoint in SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64067b",
   "metadata": {},
   "source": [
    "### Create your Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 10\n",
    "\n",
    "# Save the model to Sagemaker\n",
    "model_step = steps.ModelStep(\n",
    "    'RegisterModel',\n",
    "    model=train_step.get_expected_model(),\n",
    "    model_name=execution_input['ModelName']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97f047",
   "metadata": {},
   "source": [
    "### Create your Endpoint Configuration Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "\n",
    "endpoint_config_step = steps.EndpointConfigStep(\n",
    "    \"Create Endpoint Config\",\n",
    "    endpoint_config_name=execution_input[\"ModelName\"],\n",
    "    model_name=execution_input[\"ModelName\"],\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9f8ab",
   "metadata": {},
   "source": [
    "### Create your Endpoint Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89eabc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12\n",
    "\n",
    "endpoint_step = steps.EndpointStep(\n",
    "    \"Create Endpoint\",\n",
    "    endpoint_name=execution_input[\"EndpointName\"],\n",
    "    endpoint_config_name=execution_input[\"ModelName\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e17930",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Task 6: Define the Step Function Workflow\n",
    "\n",
    "Run throught the cells below to:\n",
    "1. Define the order of the steps `cell 13` \n",
    "1. Define the order of the Step Function Wokflow `cell 14` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 13\n",
    "\n",
    "# Defining the steps order\n",
    "workflow_definition = steps.Chain(\n",
    "    [\n",
    "        preprocess_step,\n",
    "        train_step,\n",
    "        model_step,\n",
    "        endpoint_config_step,\n",
    "        endpoint_step\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 14\n",
    "\n",
    "workflow = Workflow(\n",
    "    name=\"sagemaker-pred-maintenance-pipeline\",\n",
    "    definition=workflow_definition,\n",
    "    role=workflow_execution_role,\n",
    "    execution_input=execution_input,\n",
    ")\n",
    "\n",
    "workflow.create()\n",
    "\n",
    "workflow.update(definition=workflow_definition, role=workflow_execution_role)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9813a5",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 7: Start and Monitor the Step Function Execution\n",
    "\n",
    "* Start the pipeline in `cell 15` \n",
    "* Monitor progress in [Step Function Console](https://eu-west-2.console.aws.amazon.com/states/home?region=eu-west-2#/statemachines/view/arn:aws:states:eu-west-2:273786305532:stateMachine:sagemaker-pred-maintenance-pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 15\n",
    "\n",
    "gid = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "inputs = {\n",
    "    \"TrainingJobName\": \"sagemaker-xgboost-job-{}\".format(gid),\n",
    "    \"ModelName\": \"sagemaker-xgboost-job-{}\".format(gid),\n",
    "    \"EndpointName\": \"sagemaker-xgboost-job-{}\".format(gid),\n",
    "    \"ProcessingJobName\": \"sagemaker-xgboost-job-{}\".format(gid),\n",
    "}\n",
    "\n",
    "execution = workflow.execute(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43369bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
